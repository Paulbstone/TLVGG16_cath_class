{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE PART OF CODE DESIGNATED CONFIG IN THE ORIGINAL, I HAVE IT IN the SAME NOTEBOOK\n",
    "\n",
    "#https://www.pyimagesearch.com/2019/06/03/fine-tuning-with-keras-and-deep-learning/\n",
    "\n",
    "# import the necessary packages\n",
    "import os\n",
    "\n",
    "# initialize the path to the *original* input directory of images\n",
    "ORIG_INPUT_DATASET = \"Food-11\"\n",
    "# initialize the base path to the *new* directory that will contain\n",
    "# our images after computing the training and testing split\n",
    "BASE_PATH = \"dataset\"\n",
    "\n",
    "# define the names of the training, testing, and validation\n",
    "# directories\n",
    "TRAIN = \"training\"\n",
    "TEST = \"evaluation\"\n",
    "VAL = \"validation\"\n",
    "\n",
    "# initialize the list of class label names\n",
    "CLASSES = [\"hit\", \"no_hit\"]\n",
    "\n",
    "# set the batch size when fine-tuning\n",
    "BATCH_SIZE = 16\n",
    "# initialize the label encoder file path and the output directory to\n",
    "# where the extracted features (in CSV file format) will be stored\n",
    "LE_PATH = os.path.sep.join([\"output\", \"le.cpickle\"])\n",
    "BASE_CSV_PATH = \"output\"\n",
    "# set the path to the serialized model after training\n",
    "MODEL_PATH = os.path.sep.join([\"output\", \"food11.model\"])\n",
    "# define the path to the output training history plots\n",
    "UNFROZEN_PLOT_PATH = os.path.sep.join([\"output\", \"unfrozen.png\"])\n",
    "WARMUP_PLOT_PATH = os.path.sep.join([\"output\", \"warmup.png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT \n",
    "\n",
    "Move the files to the correct File structure (done already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing 'training split'...\n",
      "[INFO] processing 'evaluation split'...\n",
      "[INFO] processing 'validation split'...\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from imutils import paths\n",
    "import shutil\n",
    "import os\n",
    "# loop over the data splits\n",
    "for split in (TRAIN, TEST, VAL):\n",
    "    # grab all image paths in the current split\n",
    "    print(\"[INFO] processing '{} split'...\".format(split))\n",
    "    p = os.path.sep.join([ORIG_INPUT_DATASET, split])\n",
    "    imagePaths = list(paths.list_images(p))\n",
    "    #print(imagePaths)\n",
    "    # loop over the image paths\n",
    "    for imagePath in imagePaths:\n",
    "        # extract class label from the filename\n",
    "        filename = imagePath.split(os.path.sep)[-1]\n",
    "        label = CLASSES[int(filename.split(\"_\")[0])]\n",
    "        #print(label)\n",
    "        # construct the path to the output directory\n",
    "        dirPath = os.path.sep.join([BASE_PATH, split, label])\n",
    "        \n",
    "        # if the output directory does not exist, create it\n",
    "        if not os.path.exists(dirPath):\n",
    "            os.makedirs(dirPath)\n",
    "            \n",
    "        # construct the path to the output image file and copy it\n",
    "        p = os.path.sep.join([dirPath, filename])\n",
    "        shutil.copy2(imagePath, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "NEXT - TRAIN MODEL CODE\n",
    "\n",
    "From here is the implementation of the training code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_training(H, N, plotPath):\n",
    "    # construct a plot that plots and saves the training history\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\\validation\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# derive the paths to the training, validation, and testing\n",
    "# directories\n",
    "trainPath = os.path.sep.join([BASE_PATH, TRAIN])\n",
    "valPath = os.path.sep.join([BASE_PATH, VAL])\n",
    "testPath = os.path.sep.join([BASE_PATH, TEST])\n",
    "\n",
    "print(valPath)\n",
    "# determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(trainPath)))\n",
    "totalVal = len(list(paths.list_images(valPath)))\n",
    "totalTest = len(list(paths.list_images(testPath)))\n",
    "print(totalTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator()\n",
    "\n",
    "# define the ImageNet mean subtraction (in RGB order) and set the\n",
    "# the mean subtraction value for each of the data augmentation\n",
    "# objects\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 images belonging to 2 classes.\n",
      "Found 64 images belonging to 2 classes.\n",
      "Found 64 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    trainPath,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "    valPath,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "    testPath,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next\n",
    "\n",
    "\n",
    "Determine class weights for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0, 1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "counter = Counter(trainGen.classes)                          \n",
    "max_val = float(max(counter.values()))       \n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# load the VGG16 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "# new fc activation for binary cross entropy\n",
    "#headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
    "#old fc layer\n",
    "headModel = Dense(len(CLASSES), activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "WARNING:tensorflow:From C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 7.5971 - acc: 0.4688\n",
      "12/12 [==============================] - 28s 2s/step - loss: 4.9960 - acc: 0.4792 - val_loss: 7.5971 - val_acc: 0.4688\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 7.4866 - acc: 0.4688\n",
      "12/12 [==============================] - 22s 2s/step - loss: 6.5212 - acc: 0.4792 - val_loss: 7.4866 - val_acc: 0.4688\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 7.5077 - acc: 0.5156\n",
      "12/12 [==============================] - 22s 2s/step - loss: 6.0915 - acc: 0.5000 - val_loss: 7.5077 - val_acc: 0.5156\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 4.8149 - acc: 0.5625\n",
      "12/12 [==============================] - 22s 2s/step - loss: 5.6937 - acc: 0.5052 - val_loss: 4.8149 - val_acc: 0.5625\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 8.0590 - acc: 0.5000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 6.7164 - acc: 0.5365 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 7.1036 - acc: 0.5000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 7.4285 - acc: 0.4688 - val_loss: 7.1036 - val_acc: 0.5000\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 6.5347 - acc: 0.5625\n",
      "12/12 [==============================] - 23s 2s/step - loss: 5.2856 - acc: 0.5625 - val_loss: 6.5347 - val_acc: 0.5625\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 4.1742 - acc: 0.5781\n",
      "12/12 [==============================] - 23s 2s/step - loss: 5.5915 - acc: 0.5729 - val_loss: 4.1742 - val_acc: 0.5781\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 5.9187 - acc: 0.5469\n",
      "12/12 [==============================] - 22s 2s/step - loss: 5.5116 - acc: 0.5521 - val_loss: 5.9187 - val_acc: 0.5469\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 5.9278 - acc: 0.5469\n",
      "12/12 [==============================] - 22s 2s/step - loss: 6.1432 - acc: 0.5469 - val_loss: 5.9278 - val_acc: 0.5469\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 5.4765 - acc: 0.4844\n",
      "12/12 [==============================] - 22s 2s/step - loss: 5.5887 - acc: 0.5208 - val_loss: 5.4765 - val_acc: 0.4844\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 5.1863 - acc: 0.6094\n",
      "12/12 [==============================] - 22s 2s/step - loss: 5.2027 - acc: 0.5781 - val_loss: 5.1863 - val_acc: 0.6094\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 4.6756 - acc: 0.5938\n",
      "12/12 [==============================] - 22s 2s/step - loss: 5.0687 - acc: 0.5521 - val_loss: 4.6756 - val_acc: 0.5938\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 6.2576 - acc: 0.5625\n",
      "12/12 [==============================] - 22s 2s/step - loss: 4.5518 - acc: 0.5938 - val_loss: 6.2576 - val_acc: 0.5625\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 6.7402 - acc: 0.4844\n",
      "12/12 [==============================] - 23s 2s/step - loss: 4.5847 - acc: 0.5521 - val_loss: 6.7402 - val_acc: 0.4844\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 5.8054 - acc: 0.5469\n",
      "12/12 [==============================] - 23s 2s/step - loss: 4.2533 - acc: 0.5417 - val_loss: 5.8054 - val_acc: 0.5469\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 4.8917 - acc: 0.5000\n",
      "12/12 [==============================] - 22s 2s/step - loss: 3.6942 - acc: 0.6198 - val_loss: 4.8917 - val_acc: 0.5000\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 4.5692 - acc: 0.5625\n",
      "12/12 [==============================] - 22s 2s/step - loss: 3.1182 - acc: 0.6094 - val_loss: 4.5692 - val_acc: 0.5625\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 3.1873 - acc: 0.5938\n",
      "12/12 [==============================] - 23s 2s/step - loss: 3.1325 - acc: 0.6094 - val_loss: 3.1873 - val_acc: 0.5938\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 2.4939 - acc: 0.5938\n",
      "12/12 [==============================] - 22s 2s/step - loss: 3.4832 - acc: 0.5312 - val_loss: 2.4939 - val_acc: 0.5938\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 2.5641 - acc: 0.6406\n",
      "12/12 [==============================] - 22s 2s/step - loss: 3.2234 - acc: 0.5677 - val_loss: 2.5641 - val_acc: 0.6406\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.8331 - acc: 0.6719\n",
      "12/12 [==============================] - 22s 2s/step - loss: 2.7522 - acc: 0.5833 - val_loss: 1.8331 - val_acc: 0.6719\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 2.1477 - acc: 0.5781\n",
      "12/12 [==============================] - 22s 2s/step - loss: 2.4340 - acc: 0.5677 - val_loss: 2.1477 - val_acc: 0.5781\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 2.1947 - acc: 0.5625\n",
      "12/12 [==============================] - 22s 2s/step - loss: 2.3789 - acc: 0.5365 - val_loss: 2.1947 - val_acc: 0.5625\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.8359 - acc: 0.6875\n",
      "12/12 [==============================] - 22s 2s/step - loss: 1.8858 - acc: 0.5781 - val_loss: 0.8359 - val_acc: 0.6875\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.0383 - acc: 0.5938\n",
      "12/12 [==============================] - 22s 2s/step - loss: 1.6792 - acc: 0.5938 - val_loss: 1.0383 - val_acc: 0.5938\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.5684 - acc: 0.7188\n",
      "12/12 [==============================] - 22s 2s/step - loss: 1.2504 - acc: 0.6406 - val_loss: 0.5684 - val_acc: 0.7188\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7616 - acc: 0.6719\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.9945 - acc: 0.6406 - val_loss: 0.7616 - val_acc: 0.6719\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6230 - acc: 0.6719\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.9870 - acc: 0.5938 - val_loss: 0.6230 - val_acc: 0.6719\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8419 - acc: 0.6562\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.1551 - acc: 0.5573 - val_loss: 0.8419 - val_acc: 0.6562\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.5902 - acc: 0.6719\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.0738 - acc: 0.5938 - val_loss: 0.5902 - val_acc: 0.6719\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4767 - acc: 0.7500\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.9627 - acc: 0.5625 - val_loss: 0.4767 - val_acc: 0.7500\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4940 - acc: 0.7188\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.9769 - acc: 0.5677 - val_loss: 0.4940 - val_acc: 0.7188\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4818 - acc: 0.7188\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.9536 - acc: 0.5781 - val_loss: 0.4818 - val_acc: 0.7188\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5533 - acc: 0.7031\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.7900 - acc: 0.5885 - val_loss: 0.5533 - val_acc: 0.7031\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5972 - acc: 0.6875\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.8403 - acc: 0.5885 - val_loss: 0.5972 - val_acc: 0.6875\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4953 - acc: 0.6562\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.7215 - acc: 0.6510 - val_loss: 0.4953 - val_acc: 0.6562\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4916 - acc: 0.7031\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.7649 - acc: 0.6042 - val_loss: 0.4916 - val_acc: 0.7031\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5293 - acc: 0.6719\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.7043 - acc: 0.6719 - val_loss: 0.5293 - val_acc: 0.6719\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5227 - acc: 0.7031\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6543 - acc: 0.6771 - val_loss: 0.5227 - val_acc: 0.7031\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4882 - acc: 0.7188\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.7536 - acc: 0.6094 - val_loss: 0.4882 - val_acc: 0.7188\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4854 - acc: 0.7656\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.6774 - acc: 0.6615 - val_loss: 0.4854 - val_acc: 0.7656\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5124 - acc: 0.7344\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6989 - acc: 0.6927 - val_loss: 0.5124 - val_acc: 0.7344\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5028 - acc: 0.7188\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6545 - acc: 0.6615 - val_loss: 0.5028 - val_acc: 0.7188\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4697 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6869 - acc: 0.6406 - val_loss: 0.4697 - val_acc: 0.8125\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4760 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6433 - acc: 0.6354 - val_loss: 0.4760 - val_acc: 0.7812\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4552 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6546 - acc: 0.6875 - val_loss: 0.4552 - val_acc: 0.8125\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4910 - acc: 0.7500\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.6684 - acc: 0.6458 - val_loss: 0.4910 - val_acc: 0.7500\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4804 - acc: 0.7656\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6915 - acc: 0.6562 - val_loss: 0.4804 - val_acc: 0.7656\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4900 - acc: 0.7969\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.6459 - acc: 0.6250 - val_loss: 0.4900 - val_acc: 0.7969\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5149 - acc: 0.7031\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.7475 - acc: 0.6042 - val_loss: 0.5149 - val_acc: 0.7031\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5302 - acc: 0.6875\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.7166 - acc: 0.6146 - val_loss: 0.5302 - val_acc: 0.6875\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4704 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6467 - acc: 0.6667 - val_loss: 0.4704 - val_acc: 0.7812\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4450 - acc: 0.7969\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.6580 - acc: 0.6771 - val_loss: 0.4450 - val_acc: 0.7969\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4254 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.7483 - acc: 0.6042 - val_loss: 0.4254 - val_acc: 0.8594\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4288 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6671 - acc: 0.6771 - val_loss: 0.4288 - val_acc: 0.8125\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4333 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.7162 - acc: 0.6146 - val_loss: 0.4333 - val_acc: 0.8438\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4320 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6456 - acc: 0.6406 - val_loss: 0.4320 - val_acc: 0.8750\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4540 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6413 - acc: 0.6615 - val_loss: 0.4540 - val_acc: 0.7969\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4436 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6060 - acc: 0.6979 - val_loss: 0.4436 - val_acc: 0.8125\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4562 - acc: 0.7656\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6567 - acc: 0.5885 - val_loss: 0.4562 - val_acc: 0.7656\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5325 - acc: 0.6250\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6225 - acc: 0.6615 - val_loss: 0.5325 - val_acc: 0.6250\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4737 - acc: 0.7500\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6731 - acc: 0.6302 - val_loss: 0.4737 - val_acc: 0.7500\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4519 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6277 - acc: 0.6875 - val_loss: 0.4519 - val_acc: 0.7812\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4451 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6743 - acc: 0.6354 - val_loss: 0.4451 - val_acc: 0.8281\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4559 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6362 - acc: 0.6302 - val_loss: 0.4559 - val_acc: 0.8438\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4530 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6830 - acc: 0.5938 - val_loss: 0.4530 - val_acc: 0.8281\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4898 - acc: 0.8125\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.5861 - acc: 0.6771 - val_loss: 0.4898 - val_acc: 0.8125\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5299 - acc: 0.7500\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5921 - acc: 0.6458 - val_loss: 0.5299 - val_acc: 0.7500\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5078 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5666 - acc: 0.7083 - val_loss: 0.5078 - val_acc: 0.7969\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5218 - acc: 0.7500\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6944 - acc: 0.6146 - val_loss: 0.5218 - val_acc: 0.7500\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4884 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5826 - acc: 0.7031 - val_loss: 0.4884 - val_acc: 0.8125\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4631 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6369 - acc: 0.6406 - val_loss: 0.4631 - val_acc: 0.7812\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4870 - acc: 0.7656\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6122 - acc: 0.6875 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4813 - acc: 0.7656\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5709 - acc: 0.6927 - val_loss: 0.4813 - val_acc: 0.7656\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4953 - acc: 0.7656\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6587 - acc: 0.5990 - val_loss: 0.4953 - val_acc: 0.7656\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5231 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6301 - acc: 0.6510 - val_loss: 0.5231 - val_acc: 0.7812\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5256 - acc: 0.7188\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6407 - acc: 0.6302 - val_loss: 0.5256 - val_acc: 0.7188\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5215 - acc: 0.7500\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5986 - acc: 0.7135 - val_loss: 0.5215 - val_acc: 0.7500\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5532 - acc: 0.7500\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6004 - acc: 0.6615 - val_loss: 0.5532 - val_acc: 0.7500\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4959 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6172 - acc: 0.6250 - val_loss: 0.4959 - val_acc: 0.7812\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4586 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5929 - acc: 0.6719 - val_loss: 0.4586 - val_acc: 0.8438\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4453 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5983 - acc: 0.6823 - val_loss: 0.4453 - val_acc: 0.8125\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4464 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5972 - acc: 0.6667 - val_loss: 0.4464 - val_acc: 0.7969\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.4706 - acc: 0.7812\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.6165 - acc: 0.6615 - val_loss: 0.4706 - val_acc: 0.7812\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.4536 - acc: 0.7969\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5777 - acc: 0.7031 - val_loss: 0.4536 - val_acc: 0.7969\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4543 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5565 - acc: 0.6979 - val_loss: 0.4543 - val_acc: 0.8125\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4668 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6697 - acc: 0.6406 - val_loss: 0.4668 - val_acc: 0.7969\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4701 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6422 - acc: 0.6354 - val_loss: 0.4701 - val_acc: 0.7969\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4683 - acc: 0.7656\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6474 - acc: 0.6510 - val_loss: 0.4683 - val_acc: 0.7656\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4546 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6278 - acc: 0.6667 - val_loss: 0.4546 - val_acc: 0.7812\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4833 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6098 - acc: 0.6667 - val_loss: 0.4833 - val_acc: 0.7969\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4846 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5586 - acc: 0.7135 - val_loss: 0.4846 - val_acc: 0.7969\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4523 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6038 - acc: 0.6198 - val_loss: 0.4523 - val_acc: 0.7812\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4719 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5968 - acc: 0.6562 - val_loss: 0.4719 - val_acc: 0.7812\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4302 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6198 - acc: 0.6562 - val_loss: 0.4302 - val_acc: 0.7969\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4302 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5988 - acc: 0.6719 - val_loss: 0.4302 - val_acc: 0.7812\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4371 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6031 - acc: 0.6719 - val_loss: 0.4371 - val_acc: 0.8125\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4280 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5748 - acc: 0.6927 - val_loss: 0.4280 - val_acc: 0.8125\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4247 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6137 - acc: 0.6615 - val_loss: 0.4247 - val_acc: 0.8281\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4292 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5176 - acc: 0.7604 - val_loss: 0.4292 - val_acc: 0.8281\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4169 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5525 - acc: 0.6979 - val_loss: 0.4169 - val_acc: 0.8281\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4283 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5378 - acc: 0.7448 - val_loss: 0.4283 - val_acc: 0.8125\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4168 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6006 - acc: 0.6823 - val_loss: 0.4168 - val_acc: 0.8594\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4195 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5837 - acc: 0.6771 - val_loss: 0.4195 - val_acc: 0.8281\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4254 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6006 - acc: 0.6615 - val_loss: 0.4254 - val_acc: 0.7969\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4552 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5467 - acc: 0.6927 - val_loss: 0.4552 - val_acc: 0.7969\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4483 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6412 - acc: 0.6250 - val_loss: 0.4483 - val_acc: 0.7969\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4204 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6029 - acc: 0.6615 - val_loss: 0.4204 - val_acc: 0.8125\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4207 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6025 - acc: 0.6719 - val_loss: 0.4207 - val_acc: 0.8438\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4024 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5787 - acc: 0.6979 - val_loss: 0.4024 - val_acc: 0.8594\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4017 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6047 - acc: 0.6979 - val_loss: 0.4017 - val_acc: 0.8750\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4124 - acc: 0.8438\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5645 - acc: 0.6979 - val_loss: 0.4124 - val_acc: 0.8438\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4249 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5652 - acc: 0.6875 - val_loss: 0.4249 - val_acc: 0.8281\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4231 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5848 - acc: 0.6719 - val_loss: 0.4231 - val_acc: 0.8281\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4389 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6368 - acc: 0.6406 - val_loss: 0.4389 - val_acc: 0.8281\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4650 - acc: 0.7344\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6203 - acc: 0.6875 - val_loss: 0.4650 - val_acc: 0.7344\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4548 - acc: 0.7656\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5798 - acc: 0.6875 - val_loss: 0.4548 - val_acc: 0.7656\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4384 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5114 - acc: 0.7344 - val_loss: 0.4384 - val_acc: 0.7969\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4319 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5760 - acc: 0.6615 - val_loss: 0.4319 - val_acc: 0.7969\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4142 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5552 - acc: 0.7188 - val_loss: 0.4142 - val_acc: 0.8281\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4124 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5621 - acc: 0.6979 - val_loss: 0.4124 - val_acc: 0.8125\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4340 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6201 - acc: 0.6562 - val_loss: 0.4340 - val_acc: 0.8125\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4270 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5944 - acc: 0.6771 - val_loss: 0.4270 - val_acc: 0.7969\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4235 - acc: 0.8125\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5537 - acc: 0.6927 - val_loss: 0.4235 - val_acc: 0.8125\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4501 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5963 - acc: 0.6875 - val_loss: 0.4501 - val_acc: 0.7969\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4141 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5874 - acc: 0.7031 - val_loss: 0.4141 - val_acc: 0.7969\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4026 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5023 - acc: 0.6979 - val_loss: 0.4026 - val_acc: 0.8281\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4000 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5650 - acc: 0.6510 - val_loss: 0.4000 - val_acc: 0.8438\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4072 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5959 - acc: 0.6615 - val_loss: 0.4072 - val_acc: 0.8594\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4072 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6135 - acc: 0.6406 - val_loss: 0.4072 - val_acc: 0.8594\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3962 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5689 - acc: 0.6927 - val_loss: 0.3962 - val_acc: 0.8281\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3945 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5225 - acc: 0.7292 - val_loss: 0.3945 - val_acc: 0.8281\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3923 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5730 - acc: 0.7135 - val_loss: 0.3923 - val_acc: 0.8438\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3975 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5376 - acc: 0.7292 - val_loss: 0.3975 - val_acc: 0.8438\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3951 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4915 - acc: 0.7448 - val_loss: 0.3951 - val_acc: 0.8281\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4122 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5927 - acc: 0.6771 - val_loss: 0.4122 - val_acc: 0.8281\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4106 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5838 - acc: 0.6771 - val_loss: 0.4106 - val_acc: 0.8281\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3815 - acc: 0.8594\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.5344 - acc: 0.7344 - val_loss: 0.3815 - val_acc: 0.8594\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3810 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5513 - acc: 0.6875 - val_loss: 0.3810 - val_acc: 0.8438\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4097 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5880 - acc: 0.6667 - val_loss: 0.4097 - val_acc: 0.8125\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4410 - acc: 0.7500\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4996 - acc: 0.7292 - val_loss: 0.4410 - val_acc: 0.7500\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4389 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5362 - acc: 0.6771 - val_loss: 0.4389 - val_acc: 0.7812\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4278 - acc: 0.8281\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5284 - acc: 0.7344 - val_loss: 0.4278 - val_acc: 0.8281\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4478 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5670 - acc: 0.6667 - val_loss: 0.4478 - val_acc: 0.7969\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4696 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5433 - acc: 0.7031 - val_loss: 0.4696 - val_acc: 0.7812\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4569 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5535 - acc: 0.6875 - val_loss: 0.4569 - val_acc: 0.7812\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4419 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5969 - acc: 0.6927 - val_loss: 0.4419 - val_acc: 0.7812\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4564 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5589 - acc: 0.7188 - val_loss: 0.4564 - val_acc: 0.7812\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4625 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5706 - acc: 0.6562 - val_loss: 0.4625 - val_acc: 0.7969\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4319 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5158 - acc: 0.7344 - val_loss: 0.4319 - val_acc: 0.7969\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4127 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5743 - acc: 0.6771 - val_loss: 0.4127 - val_acc: 0.7969\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4231 - acc: 0.7500\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4827 - acc: 0.7604 - val_loss: 0.4231 - val_acc: 0.7500\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4258 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5311 - acc: 0.7240 - val_loss: 0.4258 - val_acc: 0.7969\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4275 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5624 - acc: 0.7031 - val_loss: 0.4275 - val_acc: 0.8438\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4309 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5244 - acc: 0.7292 - val_loss: 0.4309 - val_acc: 0.8438\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4174 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5260 - acc: 0.7604 - val_loss: 0.4174 - val_acc: 0.8438\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3977 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5032 - acc: 0.6979 - val_loss: 0.3977 - val_acc: 0.8594\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3895 - acc: 0.8906\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5791 - acc: 0.6927 - val_loss: 0.3895 - val_acc: 0.8906\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4231 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6253 - acc: 0.6458 - val_loss: 0.4231 - val_acc: 0.8438\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4100 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5018 - acc: 0.7240 - val_loss: 0.4100 - val_acc: 0.8281\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.4223 - acc: 0.8438\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.4980 - acc: 0.7448 - val_loss: 0.4223 - val_acc: 0.8438\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.4252 - acc: 0.8594\n",
      "12/12 [==============================] - 28s 2s/step - loss: 0.5671 - acc: 0.6979 - val_loss: 0.4252 - val_acc: 0.8594\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3823 - acc: 0.8281\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.5240 - acc: 0.7448 - val_loss: 0.3823 - val_acc: 0.8281\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.3888 - acc: 0.8281\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.5883 - acc: 0.6719 - val_loss: 0.3888 - val_acc: 0.8281\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3893 - acc: 0.8438\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5246 - acc: 0.7292 - val_loss: 0.3893 - val_acc: 0.8438\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3785 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5208 - acc: 0.7135 - val_loss: 0.3785 - val_acc: 0.8125\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3770 - acc: 0.8750\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5400 - acc: 0.7448 - val_loss: 0.3770 - val_acc: 0.8750\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3718 - acc: 0.8750\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.4923 - acc: 0.7500 - val_loss: 0.3718 - val_acc: 0.8750\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3745 - acc: 0.8438\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5393 - acc: 0.7344 - val_loss: 0.3745 - val_acc: 0.8438\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3890 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5548 - acc: 0.6979 - val_loss: 0.3890 - val_acc: 0.8125\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4040 - acc: 0.7969\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.4914 - acc: 0.7396 - val_loss: 0.4040 - val_acc: 0.7969\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4086 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5264 - acc: 0.7292 - val_loss: 0.4086 - val_acc: 0.7812\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4295 - acc: 0.7812\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.5479 - acc: 0.6927 - val_loss: 0.4295 - val_acc: 0.7812\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4608 - acc: 0.7969\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5210 - acc: 0.7135 - val_loss: 0.4608 - val_acc: 0.7969\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4860 - acc: 0.7344\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.4577 - acc: 0.7708 - val_loss: 0.4860 - val_acc: 0.7344\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.4734 - acc: 0.7969\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5477 - acc: 0.7188 - val_loss: 0.4734 - val_acc: 0.7969\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4781 - acc: 0.7969\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5623 - acc: 0.7188 - val_loss: 0.4781 - val_acc: 0.7969\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4983 - acc: 0.7969\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5259 - acc: 0.7344 - val_loss: 0.4983 - val_acc: 0.7969\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.4667 - acc: 0.7969\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5473 - acc: 0.7188 - val_loss: 0.4667 - val_acc: 0.7969\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4383 - acc: 0.8281\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5460 - acc: 0.7344 - val_loss: 0.4383 - val_acc: 0.8281\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3967 - acc: 0.8438\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5249 - acc: 0.7448 - val_loss: 0.3967 - val_acc: 0.8438\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3949 - acc: 0.8438\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5827 - acc: 0.7031 - val_loss: 0.3949 - val_acc: 0.8438\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3790 - acc: 0.8594\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5127 - acc: 0.7500 - val_loss: 0.3790 - val_acc: 0.8594\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3958 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4946 - acc: 0.7344 - val_loss: 0.3958 - val_acc: 0.8438\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3702 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5173 - acc: 0.7188 - val_loss: 0.3702 - val_acc: 0.8750\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3578 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5634 - acc: 0.7083 - val_loss: 0.3578 - val_acc: 0.8750\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3373 - acc: 0.8906\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5546 - acc: 0.7240 - val_loss: 0.3373 - val_acc: 0.8906\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3328 - acc: 0.8906\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5450 - acc: 0.7292 - val_loss: 0.3328 - val_acc: 0.8906\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3576 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6118 - acc: 0.6562 - val_loss: 0.3576 - val_acc: 0.8750\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3441 - acc: 0.9062\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4672 - acc: 0.7812 - val_loss: 0.3441 - val_acc: 0.9062\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3415 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5056 - acc: 0.7604 - val_loss: 0.3415 - val_acc: 0.8750\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3352 - acc: 0.9219\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5327 - acc: 0.7656 - val_loss: 0.3352 - val_acc: 0.9219\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3340 - acc: 0.9219\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4811 - acc: 0.7500 - val_loss: 0.3340 - val_acc: 0.9219\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3508 - acc: 0.8906\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5808 - acc: 0.7135 - val_loss: 0.3508 - val_acc: 0.8906\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3569 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4954 - acc: 0.7292 - val_loss: 0.3569 - val_acc: 0.8594\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3570 - acc: 0.8594\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5393 - acc: 0.7292 - val_loss: 0.3570 - val_acc: 0.8594\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3582 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4970 - acc: 0.7552 - val_loss: 0.3582 - val_acc: 0.8438\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3504 - acc: 0.8906\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5100 - acc: 0.7552 - val_loss: 0.3504 - val_acc: 0.8906\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3524 - acc: 0.8906\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4792 - acc: 0.7708 - val_loss: 0.3524 - val_acc: 0.8906\n",
      "[INFO] evaluating after fine-tuning network head...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hit       0.94      0.91      0.92        32\n",
      "      no_hit       0.91      0.94      0.92        32\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        64\n",
      "   macro avg       0.92      0.92      0.92        64\n",
      "weighted avg       0.92      0.92      0.92        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compile our model (this needs to be done after our setting our\n",
    "# layers to being non-trainable\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=5e-5, momentum=0.9)\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "#opt = Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network for a few epochs (all other layers\n",
    "# are frozen) -- this will allow the new FC layers to start to become\n",
    "# initialized with actual \"learned\" values versus pure random\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "    x=trainGen,\n",
    "    steps_per_epoch=totalTrain // BATCH_SIZE,\n",
    "    validation_data=valGen,\n",
    "    validation_steps=totalVal // BATCH_SIZE,\n",
    "    epochs=200,\n",
    "    class_weight=class_weights)   #added class weights code\n",
    "\n",
    "# reset the testing generator and evaluate the network after\n",
    "# fine-tuning just the network head\n",
    "print(\"[INFO] evaluating after fine-tuning network head...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict(x=testGen,\n",
    "    steps=(totalTest // BATCH_SIZE) + 1)\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "    target_names=testGen.class_indices.keys()))\n",
    "#plot_training(H, 10, WARMUP_PLOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cathID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] evaluating after fine-tuning network head...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict(x=testGen,\n",
    "    steps=(totalTest // BATCH_SIZE) + 1)\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "    target_names=testGen.class_indices.keys()))\n",
    "plot_training(H, 40, WARMUP_PLOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " NEXT\n",
    " \n",
    " unfreeze the final set of CONV layers in the base model layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000001A0A4116EF0>: False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A411A550>: False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A411A780>: False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001A0A416FEB8>: False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A411AC18>: False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A41AAA20>: False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001A0A41CF668>: False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A41CF048>: False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A4205898>: False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A423C860>: False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001A0A424F898>: False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A426C2B0>: False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A42AE668>: False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A42E89E8>: False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001A0A431E940>: False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A431E588>: True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A435B0B8>: True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001A0A4391470>: True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001A0A43C99E8>: True\n"
     ]
    }
   ],
   "source": [
    "# reset our data generators\n",
    "trainGen.reset()\n",
    "valGen.reset()\n",
    "# now that the head FC layers have been trained/initialized, lets\n",
    "# unfreeze the final set of CONV layers and make them trainable\n",
    "for layer in baseModel.layers[15:]:\n",
    "    layer.trainable = True\n",
    "# loop over the layers in the model and show which ones are trainable\n",
    "# or not\n",
    "for layer in baseModel.layers:\n",
    "    print(\"{}: {}\".format(layer, layer.trainable))\n",
    "model.save(\"cathID_unfreeze\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "NEXT\n",
    "\n",
    "Retrain the final Conv block and FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "[INFO] re-compiling model...\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3471 - acc: 0.8438\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.5101 - acc: 0.7604 - val_loss: 0.3471 - val_acc: 0.8438\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3871 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4798 - acc: 0.7240 - val_loss: 0.3871 - val_acc: 0.8125\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4143 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5293 - acc: 0.7031 - val_loss: 0.4143 - val_acc: 0.8594\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3744 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4884 - acc: 0.7448 - val_loss: 0.3744 - val_acc: 0.8750\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3789 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5336 - acc: 0.6875 - val_loss: 0.3789 - val_acc: 0.8750\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4942 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4894 - acc: 0.7656 - val_loss: 0.4942 - val_acc: 0.7812\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4260 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5537 - acc: 0.7031 - val_loss: 0.4260 - val_acc: 0.7969\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5122 - acc: 0.7656\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5439 - acc: 0.7188 - val_loss: 0.5122 - val_acc: 0.7656\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5145 - acc: 0.7500\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5748 - acc: 0.7135 - val_loss: 0.5145 - val_acc: 0.7500\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4055 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5092 - acc: 0.7240 - val_loss: 0.4055 - val_acc: 0.7969\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4694 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5526 - acc: 0.7083 - val_loss: 0.4694 - val_acc: 0.7812\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4114 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5549 - acc: 0.7083 - val_loss: 0.4114 - val_acc: 0.8125\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4052 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4934 - acc: 0.7552 - val_loss: 0.4052 - val_acc: 0.7812\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3836 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5146 - acc: 0.7188 - val_loss: 0.3836 - val_acc: 0.7969\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3532 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5377 - acc: 0.6927 - val_loss: 0.3532 - val_acc: 0.8281\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3683 - acc: 0.7969\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5237 - acc: 0.7240 - val_loss: 0.3683 - val_acc: 0.7969\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4091 - acc: 0.8125\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5100 - acc: 0.7500 - val_loss: 0.4091 - val_acc: 0.8125\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3792 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5419 - acc: 0.7292 - val_loss: 0.3792 - val_acc: 0.8281\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3771 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5857 - acc: 0.7031 - val_loss: 0.3771 - val_acc: 0.8438\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3061 - acc: 0.8906\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5170 - acc: 0.7708 - val_loss: 0.3061 - val_acc: 0.8906\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3938 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5086 - acc: 0.7552 - val_loss: 0.3938 - val_acc: 0.7812\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3182 - acc: 0.8594\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5629 - acc: 0.7240 - val_loss: 0.3182 - val_acc: 0.8594\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3127 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4864 - acc: 0.7708 - val_loss: 0.3127 - val_acc: 0.8750\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2830 - acc: 0.9062\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5121 - acc: 0.7656 - val_loss: 0.2830 - val_acc: 0.9062\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3169 - acc: 0.9062\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.4938 - acc: 0.7292 - val_loss: 0.3169 - val_acc: 0.9062\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3365 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5469 - acc: 0.7188 - val_loss: 0.3365 - val_acc: 0.8281\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3128 - acc: 0.9375\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4787 - acc: 0.7708 - val_loss: 0.3128 - val_acc: 0.9375\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3532 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4933 - acc: 0.7240 - val_loss: 0.3532 - val_acc: 0.8594\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4850 - acc: 0.7656\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5377 - acc: 0.6927 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3668 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4716 - acc: 0.7448 - val_loss: 0.3668 - val_acc: 0.8438\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3854 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4874 - acc: 0.7969 - val_loss: 0.3854 - val_acc: 0.7812\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3155 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4267 - acc: 0.7969 - val_loss: 0.3155 - val_acc: 0.8438\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2855 - acc: 0.9062\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4555 - acc: 0.7396 - val_loss: 0.2855 - val_acc: 0.9062\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4003 - acc: 0.7812\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5060 - acc: 0.7188 - val_loss: 0.4003 - val_acc: 0.7812\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2957 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5008 - acc: 0.7240 - val_loss: 0.2957 - val_acc: 0.8750\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4141 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4352 - acc: 0.7917 - val_loss: 0.4141 - val_acc: 0.8281\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3093 - acc: 0.8594\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.4450 - acc: 0.7865 - val_loss: 0.3093 - val_acc: 0.8594\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2948 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4090 - acc: 0.8073 - val_loss: 0.2948 - val_acc: 0.8438\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2491 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4438 - acc: 0.7865 - val_loss: 0.2491 - val_acc: 0.8594\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2503 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3932 - acc: 0.8073 - val_loss: 0.2503 - val_acc: 0.8750\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3668 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4344 - acc: 0.7917 - val_loss: 0.3668 - val_acc: 0.8594\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2959 - acc: 0.8438\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4519 - acc: 0.7917 - val_loss: 0.2959 - val_acc: 0.8438\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2340 - acc: 0.8750\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.4109 - acc: 0.8177 - val_loss: 0.2340 - val_acc: 0.8750\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2603 - acc: 0.8594\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.4189 - acc: 0.7812 - val_loss: 0.2603 - val_acc: 0.8594\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2521 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4308 - acc: 0.7760 - val_loss: 0.2521 - val_acc: 0.8594\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2094 - acc: 0.9062\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3579 - acc: 0.8385 - val_loss: 0.2094 - val_acc: 0.9062\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2944 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3862 - acc: 0.8177 - val_loss: 0.2944 - val_acc: 0.8594\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2160 - acc: 0.9375\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3385 - acc: 0.8333 - val_loss: 0.2160 - val_acc: 0.9375\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2345 - acc: 0.9062\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3745 - acc: 0.8021 - val_loss: 0.2345 - val_acc: 0.9062\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3304 - acc: 0.8906\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3727 - acc: 0.8438 - val_loss: 0.3304 - val_acc: 0.8906\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2977 - acc: 0.8906\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4633 - acc: 0.8073 - val_loss: 0.2977 - val_acc: 0.8906\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2726 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3284 - acc: 0.8490 - val_loss: 0.2726 - val_acc: 0.8750\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2894 - acc: 0.8906\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.3491 - acc: 0.8177 - val_loss: 0.2894 - val_acc: 0.8906\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2298 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3571 - acc: 0.8385 - val_loss: 0.2298 - val_acc: 0.8750\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1706 - acc: 0.9219\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3667 - acc: 0.8438 - val_loss: 0.1706 - val_acc: 0.9219\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2079 - acc: 0.8906\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3188 - acc: 0.8542 - val_loss: 0.2079 - val_acc: 0.8906\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2336 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3398 - acc: 0.8438 - val_loss: 0.2336 - val_acc: 0.8594\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2102 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3697 - acc: 0.8229 - val_loss: 0.2102 - val_acc: 0.8594\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3192 - acc: 0.8281\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3238 - acc: 0.8438 - val_loss: 0.3192 - val_acc: 0.8281\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2447 - acc: 0.9062\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3352 - acc: 0.8385 - val_loss: 0.2447 - val_acc: 0.9062\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1929 - acc: 0.8750\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3370 - acc: 0.8438 - val_loss: 0.1929 - val_acc: 0.8750\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1892 - acc: 0.8594\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.2692 - acc: 0.8750 - val_loss: 0.1892 - val_acc: 0.8594\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2265 - acc: 0.9219\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3058 - acc: 0.8594 - val_loss: 0.2265 - val_acc: 0.9219\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2149 - acc: 0.9062\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3879 - acc: 0.8229 - val_loss: 0.2149 - val_acc: 0.9062\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.1918 - acc: 0.8906\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3141 - acc: 0.8802 - val_loss: 0.1918 - val_acc: 0.8906\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2517 - acc: 0.9062\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3042 - acc: 0.8490 - val_loss: 0.2517 - val_acc: 0.9062\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1685 - acc: 0.9219\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3099 - acc: 0.8333 - val_loss: 0.1685 - val_acc: 0.9219\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.2121 - acc: 0.9219\n",
      "12/12 [==============================] - 32s 3s/step - loss: 0.3470 - acc: 0.8438 - val_loss: 0.2121 - val_acc: 0.9219\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.1304 - acc: 0.9375\n",
      "12/12 [==============================] - 27s 2s/step - loss: 0.2946 - acc: 0.8646 - val_loss: 0.1304 - val_acc: 0.9375\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.1222 - acc: 0.9688\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.2594 - acc: 0.9010 - val_loss: 0.1222 - val_acc: 0.9688\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.1739 - acc: 0.8906\n",
      "12/12 [==============================] - 27s 2s/step - loss: 0.3020 - acc: 0.8542 - val_loss: 0.1739 - val_acc: 0.8906\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.1569 - acc: 0.9844\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.2953 - acc: 0.8542 - val_loss: 0.1569 - val_acc: 0.9844\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.2467 - acc: 0.9062\n",
      "12/12 [==============================] - 28s 2s/step - loss: 0.2484 - acc: 0.8958 - val_loss: 0.2467 - val_acc: 0.9062\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.1243 - acc: 0.9688\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.3080 - acc: 0.8542 - val_loss: 0.1243 - val_acc: 0.9688\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.1372 - acc: 0.9375\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.2872 - acc: 0.8646 - val_loss: 0.1372 - val_acc: 0.9375\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.1759 - acc: 0.9219\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.2755 - acc: 0.8802 - val_loss: 0.1759 - val_acc: 0.9219\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0978 - acc: 1.0000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.2715 - acc: 0.8802 - val_loss: 0.0978 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.1337 - acc: 0.9219\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.1849 - acc: 0.9375 - val_loss: 0.1337 - val_acc: 0.9219\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.1429 - acc: 0.9531\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.3165 - acc: 0.8750 - val_loss: 0.1429 - val_acc: 0.9531\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0953 - acc: 0.9688\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.2363 - acc: 0.8802 - val_loss: 0.0953 - val_acc: 0.9688\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.1007 - acc: 0.9688\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.1899 - acc: 0.9167 - val_loss: 0.1007 - val_acc: 0.9688\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.1432 - acc: 0.9219\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.2283 - acc: 0.9010 - val_loss: 0.1432 - val_acc: 0.9219\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.1248 - acc: 0.9219\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.2125 - acc: 0.8906 - val_loss: 0.1248 - val_acc: 0.9219\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.1129 - acc: 0.9219\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.1916 - acc: 0.9010 - val_loss: 0.1129 - val_acc: 0.9219\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0621 - acc: 1.0000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.2134 - acc: 0.9062 - val_loss: 0.0621 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.1524 - acc: 0.9531\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1681 - acc: 0.9167 - val_loss: 0.1524 - val_acc: 0.9531\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0689 - acc: 0.9688\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1357 - acc: 0.9688 - val_loss: 0.0689 - val_acc: 0.9688\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0640 - acc: 0.9844\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.2177 - acc: 0.9062 - val_loss: 0.0640 - val_acc: 0.9844\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1242 - acc: 0.9375\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.2279 - acc: 0.8958 - val_loss: 0.1242 - val_acc: 0.9375\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0750 - acc: 0.9844\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.2042 - acc: 0.9167 - val_loss: 0.0750 - val_acc: 0.9844\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.1294 - acc: 0.9219\n",
      "12/12 [==============================] - 27s 2s/step - loss: 0.1550 - acc: 0.9323 - val_loss: 0.1294 - val_acc: 0.9219\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0579 - acc: 1.0000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.2435 - acc: 0.9167 - val_loss: 0.0579 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.1428 - acc: 0.9062\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.2535 - acc: 0.8854 - val_loss: 0.1428 - val_acc: 0.9062\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.1184 - acc: 0.9531\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.2141 - acc: 0.9115 - val_loss: 0.1184 - val_acc: 0.9531\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0867 - acc: 0.9531\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.2091 - acc: 0.9062 - val_loss: 0.0867 - val_acc: 0.9531\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0509 - acc: 1.0000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.1693 - acc: 0.9479 - val_loss: 0.0509 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0748 - acc: 0.9844\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1808 - acc: 0.9167 - val_loss: 0.0748 - val_acc: 0.9844\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.1041 - acc: 0.9219\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.2073 - acc: 0.8958 - val_loss: 0.1041 - val_acc: 0.9219\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0734 - acc: 0.9688\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.2488 - acc: 0.8646 - val_loss: 0.0734 - val_acc: 0.9688\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0807 - acc: 0.9375\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1861 - acc: 0.9167 - val_loss: 0.0807 - val_acc: 0.9375\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0947 - acc: 0.9531\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.2146 - acc: 0.9115 - val_loss: 0.0947 - val_acc: 0.9531\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.1216 - acc: 0.9219\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.1952 - acc: 0.8854 - val_loss: 0.1216 - val_acc: 0.9219\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0514 - acc: 1.0000\n",
      "12/12 [==============================] - 27s 2s/step - loss: 0.1668 - acc: 0.9375 - val_loss: 0.0514 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0726 - acc: 0.9688\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.1500 - acc: 0.9375 - val_loss: 0.0726 - val_acc: 0.9688\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0322 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1267 - acc: 0.9479 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0864 - acc: 0.9688\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1397 - acc: 0.9479 - val_loss: 0.0864 - val_acc: 0.9688\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0426 - acc: 1.0000\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1421 - acc: 0.9323 - val_loss: 0.0426 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0294 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1215 - acc: 0.9740 - val_loss: 0.0294 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0716 - acc: 0.9531\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.1134 - acc: 0.9635 - val_loss: 0.0716 - val_acc: 0.9531\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0547 - acc: 0.9844\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1619 - acc: 0.9479 - val_loss: 0.0547 - val_acc: 0.9844\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0880 - acc: 0.9531\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1684 - acc: 0.9271 - val_loss: 0.0880 - val_acc: 0.9531\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0453 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1415 - acc: 0.9271 - val_loss: 0.0453 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0512 - acc: 0.9844\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1363 - acc: 0.9583 - val_loss: 0.0512 - val_acc: 0.9844\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0400 - acc: 0.9844\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1141 - acc: 0.9583 - val_loss: 0.0400 - val_acc: 0.9844\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0386 - acc: 0.9844\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1291 - acc: 0.9219 - val_loss: 0.0386 - val_acc: 0.9844\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0280 - acc: 1.0000\n",
      "12/12 [==============================] - 27s 2s/step - loss: 0.1042 - acc: 0.9531 - val_loss: 0.0280 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0798 - acc: 0.9688\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.1211 - acc: 0.9583 - val_loss: 0.0798 - val_acc: 0.9688\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0706 - acc: 0.9844\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.1292 - acc: 0.9531 - val_loss: 0.0706 - val_acc: 0.9844\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.1193 - acc: 0.9688\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1372 - acc: 0.9479 - val_loss: 0.1193 - val_acc: 0.9688\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0589 - acc: 0.9688\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.1860 - acc: 0.9167 - val_loss: 0.0589 - val_acc: 0.9688\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0692 - acc: 0.9375\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0952 - acc: 0.9740 - val_loss: 0.0692 - val_acc: 0.9375\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6860 - acc: 0.8594\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.1067 - acc: 0.9688 - val_loss: 0.6860 - val_acc: 0.8594\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.1229 - acc: 0.9375\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.2193 - acc: 0.9062 - val_loss: 0.1229 - val_acc: 0.9375\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0780 - acc: 0.9531\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1256 - acc: 0.9635 - val_loss: 0.0780 - val_acc: 0.9531\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0420 - acc: 0.9844\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.0902 - acc: 0.9583 - val_loss: 0.0420 - val_acc: 0.9844\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0550 - acc: 0.9688\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1521 - acc: 0.9219 - val_loss: 0.0550 - val_acc: 0.9688\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0132 - acc: 1.0000\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.1413 - acc: 0.9271 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0271 - acc: 1.0000\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.0981 - acc: 0.9635 - val_loss: 0.0271 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0179 - acc: 1.0000\n",
      "12/12 [==============================] - 27s 2s/step - loss: 0.1185 - acc: 0.9688 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0572 - acc: 0.9688\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1496 - acc: 0.9323 - val_loss: 0.0572 - val_acc: 0.9688\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0740 - acc: 0.9688\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1268 - acc: 0.9479 - val_loss: 0.0740 - val_acc: 0.9688\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.1655 - acc: 0.9375\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.1625 - acc: 0.9271 - val_loss: 0.1655 - val_acc: 0.9375\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0375 - acc: 1.0000\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1084 - acc: 0.9583 - val_loss: 0.0375 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.1212 - acc: 0.9688\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1426 - acc: 0.9479 - val_loss: 0.1212 - val_acc: 0.9688\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0884 - acc: 0.9688\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0991 - acc: 0.9635 - val_loss: 0.0884 - val_acc: 0.9688\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0901 - acc: 0.9688\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0698 - acc: 0.9740 - val_loss: 0.0901 - val_acc: 0.9688\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0646 - acc: 0.9844\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0861 - acc: 0.9740 - val_loss: 0.0646 - val_acc: 0.9844\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0538 - acc: 0.9688\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1389 - acc: 0.9479 - val_loss: 0.0538 - val_acc: 0.9688\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0855 - acc: 0.9688\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0824 - acc: 0.9635 - val_loss: 0.0855 - val_acc: 0.9688\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0273 - acc: 0.9844\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1197 - acc: 0.9427 - val_loss: 0.0273 - val_acc: 0.9844\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0319 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0899 - acc: 0.9583 - val_loss: 0.0319 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0128 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0851 - acc: 0.9635 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0126 - acc: 1.0000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0939 - acc: 0.9635 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0146 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0774 - acc: 0.9792 - val_loss: 0.0146 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0244 - acc: 0.9844\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1397 - acc: 0.9427 - val_loss: 0.0244 - val_acc: 0.9844\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0456 - acc: 0.9688\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1511 - acc: 0.9323 - val_loss: 0.0456 - val_acc: 0.9688\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0247 - acc: 0.9844\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.1004 - acc: 0.9479 - val_loss: 0.0247 - val_acc: 0.9844\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0175 - acc: 1.0000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0747 - acc: 0.9792 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0594 - acc: 0.9688\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0814 - acc: 0.9688 - val_loss: 0.0594 - val_acc: 0.9688\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0131 - acc: 1.0000\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.0921 - acc: 0.9740 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0160 - acc: 1.0000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.1080 - acc: 0.9583 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0128 - acc: 1.0000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0572 - acc: 0.9740 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0097 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0865 - acc: 0.9740 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0276 - acc: 0.9844\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.1284 - acc: 0.9583 - val_loss: 0.0276 - val_acc: 0.9844\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0085 - acc: 1.0000\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.0672 - acc: 0.9688 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0223 - acc: 1.0000\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.1041 - acc: 0.9583 - val_loss: 0.0223 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0070 - acc: 1.0000\n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.0781 - acc: 0.9688 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0256 - acc: 1.0000\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0841 - acc: 0.9583 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0081 - acc: 1.0000\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.0714 - acc: 0.9688 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0057 - acc: 1.0000\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0455 - acc: 0.9896 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0117 - acc: 1.0000 \n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0784 - acc: 0.9688 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0091 - acc: 1.0000\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.0391 - acc: 0.9948 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0133 - acc: 1.0000 \n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.0848 - acc: 0.9792 - val_loss: 0.0133 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0037 - acc: 1.0000\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.0873 - acc: 0.9740 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0083 - acc: 1.0000\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.0996 - acc: 0.9635 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0226 - acc: 1.0000 \n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.0687 - acc: 0.9792 - val_loss: 0.0226 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0089 - acc: 1.0000 \n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0641 - acc: 0.9844 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0199 - acc: 1.0000 \n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.0531 - acc: 0.9792 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0243 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0684 - acc: 0.9635 - val_loss: 0.0243 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0619 - acc: 0.9688 \n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1314 - acc: 0.9427 - val_loss: 0.0619 - val_acc: 0.9688\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0189 - acc: 1.0000\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0916 - acc: 0.9635 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0641 - acc: 0.9688\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1331 - acc: 0.9479 - val_loss: 0.0641 - val_acc: 0.9688\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0696 - acc: 0.9688\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1061 - acc: 0.9479 - val_loss: 0.0696 - val_acc: 0.9688\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0294 - acc: 0.9844\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0564 - acc: 0.9792 - val_loss: 0.0294 - val_acc: 0.9844\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0130 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.1102 - acc: 0.9531 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0096 - acc: 1.0000\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0826 - acc: 0.9688 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0061 - acc: 1.0000\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0492 - acc: 0.9792 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0287 - acc: 1.0000\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0490 - acc: 0.9844 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0046 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0370 - acc: 0.9844 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0114 - acc: 1.0000 \n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0487 - acc: 0.9792 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0031 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0552 - acc: 0.9740 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0032 - acc: 1.0000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0478 - acc: 0.9792 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0201 - acc: 1.0000 \n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0520 - acc: 0.9792 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0077 - acc: 1.0000 \n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0589 - acc: 0.9896 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0064 - acc: 1.0000\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0649 - acc: 0.9792 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0049 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0557 - acc: 0.9740 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0054 - acc: 1.0000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0607 - acc: 0.9896 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0238 - acc: 1.0000\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.1253 - acc: 0.9479 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0028 - acc: 1.0000\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0513 - acc: 0.9844 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0229 - acc: 1.0000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0772 - acc: 0.9688 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0105 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0541 - acc: 0.9844 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0406 - acc: 0.9844\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0565 - acc: 0.9896 - val_loss: 0.0406 - val_acc: 0.9844\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.1592 - acc: 0.9219\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.0795 - acc: 0.9740 - val_loss: 0.1592 - val_acc: 0.9219\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0067 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0421 - acc: 0.9896 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0041 - acc: 1.0000 \n",
      "12/12 [==============================] - 25s 2s/step - loss: 0.0823 - acc: 0.9583 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0170 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0726 - acc: 0.9688 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0099 - acc: 1.0000 \n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0872 - acc: 0.9688 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0689 - acc: 0.9688\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0446 - acc: 0.9844 - val_loss: 0.0689 - val_acc: 0.9688\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0099 - acc: 1.0000\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.0759 - acc: 0.9688 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0105 - acc: 1.0000\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.0403 - acc: 0.9844 - val_loss: 0.0105 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# for the changes to the model to take affect we need to recompile\n",
    "# the model, this time using SGD with a *very* small learning rate\n",
    "from tensorflow import keras\n",
    "\n",
    "reconstructed_model = keras.models.load_model(\"cathID_unfreeze\")\n",
    "\n",
    "print(\"[INFO] re-compiling model...\")\n",
    "opt = SGD(lr=1e-4, momentum=0.9)\n",
    "reconstructed_model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "# train the model again, this time fine-tuning *both* the final set\n",
    "# of CONV layers along with our set of FC layers\n",
    "H = reconstructed_model.fit(\n",
    "    x=trainGen,\n",
    "    steps_per_epoch=totalTrain // BATCH_SIZE,\n",
    "    validation_data=valGen,\n",
    "    validation_steps=totalVal // BATCH_SIZE,\n",
    "    epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cathID_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(H, 200, WARMUP_PLOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "Cathmodel = keras.models.load_model('FT_CathModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model.fit(\n",
    "    x=trainGen,\n",
    "    steps_per_epoch=totalTrain // BATCH_SIZE,\n",
    "    validation_data=valGen,\n",
    "    validation_steps=totalVal // BATCH_SIZE,\n",
    "    epochs=200)\n",
    "\n",
    "\n",
    "\n",
    "pred_train= model.predict(X_train)\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= model.predict(X_test)\n",
    "scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating after fine-tuning network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         hit       0.94      0.91      0.92        32\n",
      "      no_hit       0.91      0.94      0.92        32\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        64\n",
      "   macro avg       0.92      0.92      0.92        64\n",
      "weighted avg       0.92      0.92      0.92        64\n",
      "\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "# reset the testing generator and then use our trained model to\n",
    "# make predictions on the data\n",
    "print(\"[INFO] evaluating after fine-tuning network...\")\n",
    "testGen.reset()\n",
    "predIdxsIO = Cathmodel.predict(x=testGen,\n",
    "\tsteps=(totalTest // BATCH_SIZE) + 1)\n",
    "predIdxs = np.argmax(predIdxsIO, axis=1)\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))\n",
    "#plot_training(H, 200, UNFROZEN_PLOT_PATH)\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "Cathmodel.save(\"FT_CathModel2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5599808  0.44001913]\n",
      " [0.5061579  0.49384212]\n",
      " [0.57738036 0.42261964]\n",
      " [0.8711092  0.12889086]\n",
      " [0.90454525 0.09545477]\n",
      " [0.70914876 0.2908512 ]\n",
      " [0.94729733 0.05270264]\n",
      " [0.98259026 0.01740968]\n",
      " [0.82804257 0.17195739]\n",
      " [0.85661745 0.14338258]\n",
      " [0.8536947  0.14630528]\n",
      " [0.85492605 0.14507397]\n",
      " [0.77278817 0.22721177]\n",
      " [0.90962124 0.09037879]\n",
      " [0.23429392 0.76570606]\n",
      " [0.632005   0.36799505]\n",
      " [0.9931745  0.00682552]\n",
      " [0.98850983 0.01149023]\n",
      " [0.53811246 0.4618875 ]\n",
      " [0.6086678  0.3913322 ]\n",
      " [0.60097885 0.39902112]\n",
      " [0.5510812  0.44891882]\n",
      " [0.9937272  0.00627277]\n",
      " [0.9327568  0.06724328]\n",
      " [0.7116435  0.2883565 ]\n",
      " [0.6925104  0.3074896 ]\n",
      " [0.46096995 0.5390301 ]\n",
      " [0.4812445  0.5187555 ]\n",
      " [0.5743035  0.4256965 ]\n",
      " [0.6564564  0.34354362]\n",
      " [0.75053567 0.24946432]\n",
      " [0.96859866 0.03140134]\n",
      " [0.25632414 0.7436758 ]\n",
      " [0.02888471 0.97111535]\n",
      " [0.34882975 0.65117025]\n",
      " [0.50930214 0.49069786]\n",
      " [0.16144253 0.8385574 ]\n",
      " [0.1541764  0.84582365]\n",
      " [0.13580097 0.86419904]\n",
      " [0.11133955 0.88866043]\n",
      " [0.11335207 0.88664794]\n",
      " [0.03057028 0.9694297 ]\n",
      " [0.03689552 0.9631044 ]\n",
      " [0.15096438 0.8490356 ]\n",
      " [0.25546396 0.744536  ]\n",
      " [0.25395954 0.74604046]\n",
      " [0.11151201 0.888488  ]\n",
      " [0.21742989 0.7825701 ]\n",
      " [0.3056693  0.6943307 ]\n",
      " [0.04636392 0.95363605]\n",
      " [0.0653569  0.93464315]\n",
      " [0.07189202 0.92810804]\n",
      " [0.43713972 0.5628603 ]\n",
      " [0.11625766 0.8837424 ]\n",
      " [0.13356955 0.86643046]\n",
      " [0.39845562 0.6015444 ]\n",
      " [0.3713938  0.6286062 ]\n",
      " [0.41284984 0.58715016]\n",
      " [0.08170425 0.9182958 ]\n",
      " [0.24233958 0.7576604 ]\n",
      " [0.2687573  0.7312427 ]\n",
      " [0.2095026  0.79049736]\n",
      " [0.23678967 0.7632103 ]\n",
      " [0.8070962  0.1929038 ]]\n"
     ]
    }
   ],
   "source": [
    "print(predIdxsIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0.44001913 0.49384212 0.42261964 0.12889086 0.09545477 0.2908512\n",
      " 0.05270264 0.01740968 0.17195739 0.14338258 0.14630528 0.14507397\n",
      " 0.22721177 0.09037879 0.76570606 0.36799505 0.00682552 0.01149023\n",
      " 0.4618875  0.3913322  0.39902112 0.44891882 0.00627277 0.06724328\n",
      " 0.2883565  0.3074896  0.5390301  0.5187555  0.4256965  0.34354362\n",
      " 0.24946432 0.03140134 0.7436758  0.97111535 0.65117025 0.49069786\n",
      " 0.8385574  0.84582365 0.86419904 0.88866043 0.88664794 0.9694297\n",
      " 0.9631044  0.8490356  0.744536   0.74604046 0.888488   0.7825701\n",
      " 0.6943307  0.95363605 0.93464315 0.92810804 0.5628603  0.8837424\n",
      " 0.86643046 0.6015444  0.6286062  0.58715016 0.9182958  0.7576604\n",
      " 0.7312427  0.79049736 0.7632103  0.1929038 ]\n"
     ]
    }
   ],
   "source": [
    "print(testGen.classes)\n",
    "pred_prob = predIdxsIO[:,1]\n",
    "print(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(testGen.classes, pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966796875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "print(auc_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(4)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"roc_fig_full2\")\n",
    "\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(3)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (zoomed in at top left)')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"roc_fig2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
